{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN dimensions stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 10 15\n"
     ]
    }
   ],
   "source": [
    "data=[]\n",
    "for x in range(5):\n",
    "    data.append(x)\n",
    "n = len(data)\n",
    "for z in range(10):\n",
    "    data.append(z)\n",
    "m = len(data[n:])\n",
    "\n",
    "print(n,m, len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d9e61140876f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmodule_path\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os,re,csv,pathlib\n",
    "#Allows relative imports\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deepcat_cnn(\n",
       "  (conv1): Conv2d(1, 8, kernel_size=(15, 2), stride=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=(1, 2), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(8, 16, kernel_size=(1, 2), stride=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=(1, 2), stride=(1, 1), padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.4, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.models import *\n",
    "deepcat_cnn(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# c1 = nn.Conv2d(1, 8, kernel_size=(15,2))\n",
    "m1 = nn.MaxPool2d(kernel_size = (1,2),stride = (1,1))\n",
    "c2 = nn.Conv2d(8, 16, kernel_size = (1,2))\n",
    "m2 = nn.MaxPool2d(kernel_size = (1,2),stride = (1,1))\n",
    "\n",
    "cnn = nn.Sequential(c1,m1,c2,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "\n",
      "USING LENGTH =  12\n",
      "Input:  torch.Size([1000, 1, 15, 12])\n",
      "After Conv1: torch.Size([1000, 8, 1, 11])\n",
      "After Pool1: torch.Size([1000, 8, 1, 10])\n",
      "After Conv2: torch.Size([1000, 16, 1, 9])\n",
      "After Pool2: torch.Size([1000, 16, 1, 8])\n",
      "Dense torch.Size([1000, 10])\n",
      "Output torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "for z in range(12,13):\n",
    "    print(\"####\\n\\nUSING LENGTH = \",z)\n",
    "    x = torch.rand((1000,1,15,z),dtype=torch.float32)\n",
    "    print(\"Input: \",x.shape)\n",
    "    conv1=c1(x)\n",
    "    print(\"After Conv1:\", conv1.shape)\n",
    "    pool1=m1(conv1)\n",
    "    print(\"After Pool1:\", pool1.shape)\n",
    "    conv2=c2(pool1)\n",
    "    print(\"After Conv2:\", conv2.shape)\n",
    "    pool2=m2(conv2)\n",
    "    print(\"After Pool2:\", pool2.shape)\n",
    "    xx= (z-4)*16\n",
    "    #if z<15:\n",
    "    #    xx = 16*2\n",
    "    #elif z>=15:\n",
    "    #    xx = 16*3\n",
    "    lin = nn.Linear(xx,10)\n",
    "\n",
    "    dense1= lin(pool2.view(-1,xx))\n",
    "    print(\"Dense\",dense1.shape)\n",
    "    lin2= nn.Linear(10,2)\n",
    "    dense2= lin2(dense1)\n",
    "    print(\"Output\",dense2.shape)\n",
    "    #print(\"soft\",dense1.softmax(1))\n",
    "    #print(\"arg\",dense1.argmax(1))\n",
    "    #print(\"####\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################\n",
      " For L = 12\n",
      "input torch.Size([100, 1, 15, 12])\n",
      "after conv1 torch.Size([100, 8, 1, 11])\n",
      "after pool1 torch.Size([100, 8, 1, 10])\n",
      "After conv2 torch.Size([100, 16, 1, 9])\n",
      "After pool2 torch.Size([100, 16, 1, 8])\n",
      "Before reshape torch.Size([100, 16, 1, 8])\n",
      "reshaped torch.Size([100, 128])\n",
      "###################\n",
      "\n",
      "###################\n",
      " For L = 13\n",
      "input torch.Size([100, 1, 15, 13])\n",
      "after conv1 torch.Size([100, 8, 1, 12])\n",
      "after pool1 torch.Size([100, 8, 1, 11])\n",
      "After conv2 torch.Size([100, 16, 1, 10])\n",
      "After pool2 torch.Size([100, 16, 1, 9])\n",
      "Before reshape torch.Size([100, 16, 1, 9])\n",
      "reshaped torch.Size([100, 144])\n",
      "###################\n",
      "\n",
      "###################\n",
      " For L = 14\n",
      "input torch.Size([100, 1, 15, 14])\n",
      "after conv1 torch.Size([100, 8, 1, 13])\n",
      "after pool1 torch.Size([100, 8, 1, 12])\n",
      "After conv2 torch.Size([100, 16, 1, 11])\n",
      "After pool2 torch.Size([100, 16, 1, 10])\n",
      "Before reshape torch.Size([100, 16, 1, 10])\n",
      "reshaped torch.Size([100, 160])\n",
      "###################\n",
      "\n",
      "###################\n",
      " For L = 15\n",
      "input torch.Size([100, 1, 15, 15])\n",
      "after conv1 torch.Size([100, 8, 1, 14])\n",
      "after pool1 torch.Size([100, 8, 1, 13])\n",
      "After conv2 torch.Size([100, 16, 1, 12])\n",
      "After pool2 torch.Size([100, 16, 1, 11])\n",
      "Before reshape torch.Size([100, 16, 1, 11])\n",
      "reshaped torch.Size([100, 176])\n",
      "###################\n",
      "\n",
      "###################\n",
      " For L = 16\n",
      "input torch.Size([100, 1, 15, 16])\n",
      "after conv1 torch.Size([100, 8, 1, 15])\n",
      "after pool1 torch.Size([100, 8, 1, 14])\n",
      "After conv2 torch.Size([100, 16, 1, 13])\n",
      "After pool2 torch.Size([100, 16, 1, 12])\n",
      "Before reshape torch.Size([100, 16, 1, 12])\n",
      "reshaped torch.Size([100, 192])\n",
      "###################\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.models import deepcat_cnn\n",
    "for l in range(12,17):\n",
    "    print(\"###################\\n For L = {}\".format(l))\n",
    "    model = deepcat_cnn(l)\n",
    "    feat = torch.empty((100,1,15,l))\n",
    "    out = model(feat)\n",
    "    print(\"###################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing/AA index stuff/encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\t-8.36918251369427\t8.3031934498954\t-6.6196694564762\t13.8734139891373\t8.59531323791867\t9.79914818190207\t1.26911186662177\t-4.63752901352054\t-0.983921565990354\t4.3634243590938\t2.34365256090458\t0.343445840449375\t1.18290876288827\t0.0132558803925318\t-0.696621502763574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AAs=np.array(list('WFGAVILMPYSTNQCKRHDE'))\n",
    "curPath=os.getcwd()\n",
    "##AAidx_file='AAindexNormalized.txt' ## AA index reached AUC about 61% for L=14. Worse than AdaBoost\n",
    "##AAidx_file='AtchleyFactors.txt'  ## Atchley factors work worse than using 544 AA index\n",
    "AAidx_file='AAidx_PCA.txt' ## works like a charm!!!\n",
    "gg=open(AAidx_file)\n",
    "AAidx_Names=gg.readline().strip().split('\\t') # Get PC1,... PC15\n",
    "AAidx_Dict={} # Gets the values for each of the 15 features\n",
    "i = 0\n",
    "for ll in gg.readlines():\n",
    "    if i ==4:\n",
    "        print(ll)\n",
    "    \n",
    "    ll=ll.strip().split('\\t')\n",
    "    AA=ll[0]\n",
    "    tag=0\n",
    "    vv=[]\n",
    "    for xx in ll[1:]:\n",
    "        vv.append(float(xx))\n",
    "    if tag==1:\n",
    "        i+=1\n",
    "        continue\n",
    "    i+=1\n",
    "    AAidx_Dict[AA]=vv\n",
    "    \n",
    "Nf=len(AAidx_Dict['C']) #could've just written 15...\n",
    "\n",
    "pat=re.compile('[\\\\*_XB]')  ## non-productive CDR3 patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Save the output of the mapping AAidx_dict in the beginning of DeepCAT.py\n",
    "with open('AAidx_dict.pkl', 'wb') as f: \n",
    "    pickle.dump(AAidx_Dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 \n",
      " (20, 15) \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      " <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "AAs=np.array(list('WFGAVILMPYSTNQCKRHDE'))\n",
    "\n",
    "def OneHotEncoding(Seq):\n",
    "    Seq_aa = list(Seq) \n",
    "    Ns=len(Seq_aa)\n",
    "    OHE=np.zeros([20,Ns])\n",
    "    for ii in range(Ns):\n",
    "        aa=Seq_aa[ii]\n",
    "        vv=np.where(AAs==aa)\n",
    "        OHE[vv,ii]=1\n",
    "    OHE=OHE.astype(np.float32)\n",
    "    return OHE, vv \n",
    "#So in X (row/index) we have the amino acid \n",
    "#And in Y (columns) we have the position in the sequence\n",
    "seq = 'CASSYSTRGGSPLHF'\n",
    "temp, vv = OneHotEncoding(seq)\n",
    "print(temp.dtype,\"\\n\", temp.shape,\"\\n\",temp,\"\\n\",type(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(oneHot_encoding('CASSYSGGSPLHF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nf = number features = 15\n",
    "Nf=15\n",
    "def AAindexEncoding(Seq):\n",
    "    Ns=len(Seq)\n",
    "    AAE=np.zeros([Ns, Nf])\n",
    "    for kk in range(Ns):\n",
    "        ss=Seq[kk]\n",
    "        #print(ss, kk)\n",
    "        AAE[kk,]=AAidx_Dict[ss]\n",
    "    AAE=np.transpose(AAE.astype(np.float32))\n",
    "    return AAE\n",
    "seq = 'CASSYSGGSPLHF'\n",
    "temp = AAindexEncoding(seq)\n",
    "print(temp,temp.shape)\n",
    "#print(temp.dtype,\"\\n\", temp.shape,\"\\n\",temp,\"\\n\",type(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llt = torch.tensor([12, 13, 14, 12, 12, 15, 15, 15, 12])\n",
    "\n",
    "ll = 12\n",
    "ll1 = 15\n",
    "x= torch.tensor([1]*len(torch.where(llt==ll)[0])+[0]*len(torch.where(llt==ll1)[0]))\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### draft for generate_features_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory C:\\Users\\richi\\Documents\\EPFL\\Master\\PDM\\code\\DeepTCR_PyTorch\\notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NormalCDR3.txt',\n",
       " 'NormalCDR3_test.txt',\n",
       " 'readme.md',\n",
       " 'TumorCDR3.txt',\n",
       " 'TumorCDR3_test.txt']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current directory \n",
    "path = os.getcwd() \n",
    "print(\"Current Directory\", path) \n",
    "  \n",
    "# prints parent directory \n",
    "par = os.path.abspath(os.path.join(path, os.pardir))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('../AAidx_dict.pkl', 'rb') as f: \n",
    "    AAidx_Dict = pickle.load(f) \n",
    "def aaindex_encoding(seq):\n",
    "\t\"\"\"Encodes the AA indices to a given sequence\"\"\"\n",
    "\tn_aa = len(seq)\n",
    "\ttemp = np.zeros([n_aa, 15], dtype=np.float32)\n",
    "\tfor idx in range(n_aa):\n",
    "\t\taa = seq[idx]\n",
    "\t\ttemp[idx] = AAidx_Dict[aa]\n",
    "\ttemp = np.transpose(temp)\n",
    "\taa_encoding = torch.from_numpy(temp)\n",
    "\treturn aa_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_sequences(filename):\n",
    "\t\"\"\"read sequences from a txt, and \"\"\"\n",
    "\tif '.txt' not in filename:\n",
    "\t\tprint(\"Non .txt file given, exiting\")\n",
    "\t\treturn\n",
    "\t\t\n",
    "\tdata = []\n",
    "\twith open(filename, 'r') as f:\n",
    "\t\tfor line in f.readlines():\n",
    "\t\t\tseq = line.strip()\n",
    "\t\t\tif not seq.startswith('C') or not seq.endswith('F'):continue\n",
    "\t\t\tdata.append(seq)\n",
    "\treturn np.array(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory C:\\Users\\richi\\Documents\\EPFL\\Master\\PDM\\code\\DeepTCR_PyTorch\\notebooks\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'aaindex_encoding' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-41f1e88c505e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseqs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtumor_sequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask_tumor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPAT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;32mcontinue\u001b[0m \u001b[1;31m#Skipping a sequence if it matches an unwanted CDR3 pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maaindex_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mseqs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnormal_sequences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask_normal\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'aaindex_encoding' is not defined"
     ]
    }
   ],
   "source": [
    "# get current directory \n",
    "path = os.getcwd() \n",
    "print(\"Current Directory\", path) \n",
    "  \n",
    "# prints parent directory \n",
    "par = os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "for filename in os.listdir(par+'/TrainingData/'):\n",
    "    if '.txt' in filename:\n",
    "        test = read_sequences(par+'/TrainingData/'+filename)\n",
    "#DRAFT FOR GENERATE DATA        \n",
    "tumor_sequences = np.array(test[0:1000])\n",
    "normal_sequences = np.array(test[1000:5000])\n",
    "seqlens_tumor = np.array([len(seqs) for seqs in tumor_sequences]) \n",
    "seqlens_normal = np.array([len(seqs) for seqs in normal_sequences])\n",
    "length = 12\n",
    "mask_tumor = np.where(seqlens_tumor==length)[0]\n",
    "mask_normal = np.where(seqlens_normal==length)[0]\n",
    "#Reusing the code from DeepCAT for Labels\n",
    "labels = torch.tensor(([1]*len(mask_tumor)+[0]*len(mask_normal)), dtype=torch.int64)\n",
    "len(labels)\n",
    "data = []\n",
    "PAT = re.compile('[\\\\*_XB]')  ## non-productive CDR3 patterns\n",
    "for seqs in tumor_sequences[mask_tumor]:\n",
    "    if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "    data.append(aaindex_encoding(seqs))\n",
    "\n",
    "for seqs in normal_sequences[mask_normal]:\n",
    "    if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "    data.append(aaindex_encoding(seqs))\n",
    "data = torch.stack(data)\n",
    "\n",
    "feature_dict, label_dict = {}, {}\n",
    "features = {'x':data, 'length':length}\n",
    "feature_dict[length] = features\n",
    "label_dict[length] = labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING UNSQUEEZE DIM ISSUES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory C:\\Users\\richi\\Documents\\EPFL\\Master\\PDM\\code\\DeepTCR_PyTorch\\notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([487, 1, 15, 12])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get current directory \n",
    "import pickle\n",
    "path = os.getcwd() \n",
    "print(\"Current Directory\", path) \n",
    "#Loading the pre-set Dictionary with values from PCA1-15 AA indices\n",
    "with open('../AAidx_dict.pkl', 'rb') as f: \n",
    "    AAidx_Dict = pickle.load(f) \n",
    "  \n",
    "# prints parent directory \n",
    "par = os.path.abspath(os.path.join(path, os.pardir))\n",
    "\n",
    "AAs = np.array(list('WFGAVILMPYSTNQCKRHDE')) #Constant list of amino acids\n",
    "PAT = re.compile('[\\\\*_XB]')  ## non-productive CDR3 patterns\n",
    "\n",
    "def aaindex_encoding(seq, device):\n",
    "    \"\"\"Encodes the AA indices to a given sequence\"\"\"\n",
    "    n_aa = len(seq)\n",
    "    temp = np.zeros([n_aa, 15], dtype=np.float32)\n",
    "    for idx in range(n_aa):\n",
    "        aa = seq[idx]\n",
    "        temp[idx] = AAidx_Dict[aa]\n",
    "    temp = np.transpose(temp)\n",
    "    aa_encoding = torch.from_numpy(temp)\n",
    "    aa_encoding = aa_encoding.unsqueeze(0)\n",
    "    if device == torch.device('cuda'):\n",
    "        aa_encoding = aa_encoding.to(device)\n",
    "    return aa_encoding\n",
    "\n",
    "def generate_features_labels(tumor_sequences, normal_sequences, device):\n",
    "    \"\"\"For each CDR3 dataset (tumor and normal) sequences, get the feature vectors and labels\"\"\"\n",
    "    \n",
    "    #Normally, sequences are extracted as lists, but maybe I can modify something in read_sequences to return array instead of list\n",
    "    if type(tumor_sequences)!=np.ndarray : tumor_sequences = np.array(tumor_sequences)\n",
    "    if type(tumor_sequences)!=np.ndarray : normal_sequences = np.array(normal_sequences)\n",
    "\n",
    "    #length of each datapoint (sequence)\n",
    "    seqlens_tumor = np.array([len(seqs) for seqs in tumor_sequences]) \n",
    "    seqlens_normal = np.array([len(seqs) for seqs in normal_sequences])\n",
    "\n",
    "    feature_dict, label_dict = {}, {}\n",
    "    #Only keep sequences with length 12 to 16\n",
    "    for length in range(12,17):\n",
    "        #Using numpy to create mask for fancy indexing, converting to tensors later\n",
    "        mask_tumor = np.where(seqlens_tumor==length)[0]\n",
    "        mask_normal = np.where(seqlens_normal==length)[0]\n",
    "        #Reusing the code from DeepCAT for Labels\n",
    "        labels = torch.tensor(([1]*len(mask_tumor)+[0]*len(mask_normal)), dtype=torch.int64)\n",
    "        data = []\n",
    "\n",
    "        for seqs in tumor_sequences[mask_tumor]:\n",
    "            if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "            data.append(aaindex_encoding(seqs, device))\n",
    "\n",
    "        for seqs in normal_sequences[mask_normal]:\n",
    "            if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "            data.append(aaindex_encoding(seqs, device))\n",
    "\n",
    "        data = torch.stack(data) #Stack a list of tensors into a single tensor\n",
    "        if device == torch.device('cuda'):\n",
    "            data = data.to(device)\n",
    "        features = {'x':data, 'length':length}\n",
    "        feature_dict[length] = features\n",
    "        label_dict[length] = labels \n",
    "\n",
    "    return feature_dict, label_dict\n",
    "\n",
    "for filename in os.listdir(par+'/TrainingData/'):\n",
    "    if '.txt' in filename:\n",
    "        test = read_sequences(par+'/TrainingData/'+filename)\n",
    "feats, lab = generate_features_labels(tumor_sequences, normal_sequences, 'cuda')\n",
    "feats[12]['x'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
