{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "obvious-crash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "#Allows relative imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports \n",
    "from src.preprocessing import *\n",
    "from src.models import *\n",
    "from src.train_eval_helpers import *\n",
    "from src.plots import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "#checking gpu status\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "\n",
    "RANGE = range(12,17)\n",
    "TRAINDIR = '../TrainingData/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-michigan",
   "metadata": {},
   "source": [
    "### Parsing NaÃ¯ve TCR db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "domestic-basket",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "epitope_map = {\n",
    "    \"ELAGIGILTV\" : 1 #Melanoma MLANA\n",
    "    ,\"GILGFVFTL\"  : 0 #Influenza A M gene\n",
    "    ,\"SLFNTVATLY\" : 0 #HIV\n",
    "    ,\"RMFPNAPYL\" : 1 #WT1\n",
    "    ,\"LLDFVRFMGV\" : 1 #EBNA-B EBV but also linked to \n",
    "    ,\"GLCTLVAML\" : 1 #BMLF1 ebv\n",
    "    ,\"LLFGYPVYV\" : 0 #HTLV-1 Tax\n",
    "    ,\"SLLMWITQV\" : 1 #well known squamous cell NY-ESO\n",
    "    ,\"FLYALALLL\" : 1 #EBV LMP2A, but linked to lymphoma\n",
    "    ,\"FLASKIGRLV\" : 0 # PLA2G6 phospholipase\n",
    "    ,\"MLDLQPETT\" : 1 #HPV E7\n",
    "    ,\"IMDQVPFSV\" : 1 #PMEL melanosome....\n",
    "    ,\"YLLEMLWRL\" : 1 #EBV lmp1 viral oncogene\n",
    "    ,\"KVLEYVIKV\" : 1 #MAGE A1\n",
    "    ,\"RTLNAWVKV\" : 0 #HIV gag1\n",
    "    ,\"KTWGQYWQV\" : 1 #PMEL\n",
    "    ,\"YLNDHLEPWI\" : 1 #BCL-2-l1\n",
    "    ,\"SLFNTVATL\" : 0 #HIV Gag 1\n",
    "    ,\"CLLWSFQTSA\" : 0 #tyr (ALBINISM)\n",
    "    ,\"ILKEPVHGV\" : 0 #HIV1 POL\n",
    "    ,\"CLLGTYTQDV\" : 0 #KANAMYCYN KANJ (ANTIBIO)\n",
    "    ,\"NLVPMVATV\" :  0 #H CMV\n",
    "    ,\"KLQCVDLHV\" : 0 # klk3\n",
    "    ,\"ELAGIGLTV\" : 1 #MLANA\n",
    "    ,\"VLEETSVML\" : 0 #CMV IE1\n",
    "    ,\"YVLDHLIVV\" :  0 #HPV brlf1\n",
    "    ,\"FLGKIWPSHK\" : 0 # HIV gag1\n",
    "    ,'KVAELVHFL' : 1 #melanoma associated antigen 9\n",
    "    ,\"CLNEYHLFL\" : 0 # human NDC1\n",
    "    ,\"AMFWSVPTV\" : 0 #TKT phosphate glycolysis \n",
    "    ,\"FLYNLLTRV\" :  0 #SEC24A\n",
    "    ,\"KLMNIQQKL\" : 1 #AKAP13\n",
    "    ,\"IILVAVPHV\" : 0 #EXOC8\n",
    "    ,\"MLGEQLFPL\" : 0 #PABPC1\n",
    "    ,\"YILEETSVM\" : 0 # CMV IE1\n",
    "    ,\"CINGVCWTV\" :  1 #NS3 Hep C??\n",
    "    ,\"KLSALGINAV\" : 1 #NS3 Hep C??\n",
    "    ,\"LLWNGPMAV\" :  1 #NS4B Hep C??\n",
    "    ,\"TLNAWVKVV\" : 0 #HIV GAG1\n",
    "    ,\"KINAWIKVV\" : 0 #HIV gag\n",
    "    ,\"SLYNTVATL\" : 0 #HIV gag\n",
    "    ,\"CVNGSCFTV\" : 0 #Influenza A\n",
    "    ,\"ARNLVPMVATVQGQN\" : 0 #pp65\n",
    "    ,\"LSEFCRVLCCYVLEE\" : 0 #CMV IE1\n",
    "    ,\"LLFGYAVYV\" : 0 # HLTV tax\n",
    "    ,\"LLFGYPRYV\" : 0 #HLTV tax\n",
    "    ,\"SLLMWITQC\" : 1 #NY-ESO-1\n",
    "    ,\"LLFGKPVYV\" : 0 #HLTV tax\n",
    "    ,\"LLFGPVYV\" : 0 #HLTV tax\n",
    "    ,\"MLWGYLQYV\" : 0 #HLTV tax\n",
    "    ,\"LGYGFVNYI\" : 0 #TAX\n",
    "    ,\"AAGIGILTV\" : 1 #MLANA\n",
    "    ,\"LLFGFPVYV\" : 0 #tax\n",
    "    ,\"ALWGPDPAAA\" : 0 #Insuline INS\n",
    "    ,\"ELAAIGILTV\" : 1 #MLANA\n",
    "    ,\"ELAGIGALTV\" : 1 #MLANA\n",
    "    ,\"ILAKFLHWL\" : 1 #TERT\n",
    "    ,\"EAAGIGILTV\" : 1 # MLANA\n",
    "    ,\"LLFGYPVAV\" : 0 #Tax HTLV\n",
    "    ,\"ALGIGILTV\" : 1 #MLANA\n",
    "    ,\"LLLGIGILV\" : 0 #BST2\n",
    "    ,\"KLVALGINAV\" : 1 #NS3 hepc\n",
    "    ,\"CLGGLLTMV\" : 1 #LMP2A\n",
    "    ,\"NLSALGIFST\" : 0#IGF2BP2\n",
    "    ,\"MLNIPSINV\" :0#pp65\n",
    "    ,\"VAANIVLTV\" : 0#SLC30A8\n",
    "    ,'SLYNTVATLY':0 #HIV gag\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "industrial-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "AAs= ['A','R','N','D','B','C','E','Q','Z','G',\n",
    "'H','I','L','K','M','F','P','S','T','W','Y','V']\n",
    "def filter_df(df, v = False):\n",
    "    df = df.dropna(subset=['amino_acid'])\\\n",
    "           .query('amino_acid.str.len()>=12 & amino_acid.str.len()<=16')\\\n",
    "           .query(\"amino_acid.str.startswith('C') & amino_acid.str.endswith('F')\")\\\n",
    "           .query('not amino_acid.str.contains(\"\\*\")')\\\n",
    "           .query('not amino_acid.str.contains(\"\\~\")')\n",
    "    df['len'] = df.amino_acid.str.len()\n",
    "    df.drop_duplicates(subset='amino_acid',inplace=True)\n",
    "    return df\n",
    "\n",
    "#manual 1hot encode lol\n",
    "AA_KEYS = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',\n",
    "           'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "char_to_int = dict((c,i) for i,c in enumerate(AA_KEYS))\n",
    "int_to_char = dict((i,c) for i,c in enumerate(AA_KEYS))\n",
    "\n",
    "def onehot_aa(seq):\n",
    "    int_encoded = [char_to_int[char] for char in seq]\n",
    "    onehot_encoded = list()\n",
    "    for value in int_encoded:\n",
    "        letter = [0 for _ in range(len(AA_KEYS))]\n",
    "        letter[value] = 1\n",
    "        onehot_encoded.append(letter)\n",
    "    return np.array(onehot_encoded).flatten()\n",
    "\n",
    "from sklearn.decomposition import PCA \n",
    "\n",
    "def get_reduc(df, n=3):#, top=100):\n",
    "    #Getting onehot features for PCA\n",
    "    pca = PCA(n_components=n)\n",
    "    tmp = df.copy()\n",
    "    X = np.array([x for x in df['oh']])\n",
    "    print(X.shape, type(X))\n",
    "    comp = pca.fit_transform(X)\n",
    "    print(\"Explained var ratios :\",pca.explained_variance_ratio_)\n",
    "    print(\"Explained var : \",pca.explained_variance_)\n",
    "    for i in range(n):\n",
    "        tmp['PCA'+str(i+1)]=comp[:,i]\n",
    "    var_ratio = pca.explained_variance_ratio_.tolist()\n",
    "    var_ratio = ['{:g}'.format(float('{:.3g}'.format(i))) for i in var_ratio]\n",
    "    tmp['var_ratios'] = [var_ratio for _ in range(len(tmp))]\n",
    "    return tmp\n",
    "\n",
    "def get_pca(df,n=3):\n",
    "    df = df.copy()\n",
    "    df['oh'] = df['amino_acid'].apply(onehot_aa)\n",
    "    output = get_reduc(df,n)\n",
    "    return output\n",
    "\n",
    "def plot_pca(df, hue,name):\n",
    "    ll = df.len.unique().item()\n",
    "    vars_=[z for z in df.columns if z.startswith('PCA')]\n",
    "    g = sns.PairGrid(df, x_vars = vars_,\n",
    "                     y_vars = vars_,\n",
    "                     diag_sharey=False, hue=hue)\n",
    "                     #hue_kws = {'markers':['x','x','+','+']})\n",
    "    g.fig.suptitle('{} TCR, PCA with {} components for L = {}'\\\n",
    "                   '\\nExplained variance ratios : {}'.format(name,len(vars_),ll, \n",
    "                                                                 df.var_ratios.values[0]), fontweight='bold')\n",
    "    g.fig.subplots_adjust(top=0.92)\n",
    "    g.map_lower(sns.scatterplot, style = df['label'],\n",
    "                markers=['X','X','P','P'],\n",
    "                sizes = [0.2,0.2,0.2,0.1], alpha=0.75)#,0.75,0.75,0.5])\n",
    "    g.map_upper(sns.kdeplot)\n",
    "    g.map_diag(sns.kdeplot)\n",
    "    g.add_legend()\n",
    "    plt.savefig('{}_tcr_PCA_{}comp_L{}.jpg'.format(name, len(vars_),ll), dpi=300)\n",
    "    \n",
    "sns.set_palette(\"husl\", n_colors=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-stopping",
   "metadata": {},
   "source": [
    "### Subsampling naive set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "involved-salad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../training_data_new/training_data_curated/sampled_10p_naive_db.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "legendary-norwegian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train naive sample size :  37917\n",
      "test naive sample size :  18738\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "trbv = sample_df.TRBV.unique()\n",
    "trbj = sample_df.TRBJ.unique()\n",
    "sample_df = filter_df(sample_df)\n",
    "combo = product(trbv,trbj)\n",
    "#result df\n",
    "i=0\n",
    "total = 754\n",
    "naive_train = pd.DataFrame()\n",
    "naive_test = pd.DataFrame()\n",
    "for V,J in combo:  \n",
    "    print('{:.2%} done'.format(i), end='\\r')\n",
    "    i+=1/total\n",
    "    #Sampling combo and shuffling\n",
    "    sub = sample_df.query('TRBV==@V and TRBJ==@J').sample(frac=1)\n",
    "    for l in range(12,17):\n",
    "        #Getting tmp of that len, then splitting into two to ensure there's no \n",
    "        #overlap\n",
    "        tmp = sub.query('len==@l')\n",
    "        tmp_train = tmp[0:math.floor(len(tmp)/2)]\n",
    "        tmp_test = tmp[math.floor(len(tmp)/2):-1]\n",
    "        naive_train = naive_train.append(tmp_train.sample(frac=0.2), ignore_index=True)\n",
    "        naive_test = naive_test.append(tmp_test.sample(frac=0.1), ignore_index=True)\n",
    "print(\"train naive sample size : \", len(naive_train))\n",
    "print(\"test naive sample size : \", len(naive_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-freedom",
   "metadata": {},
   "source": [
    "### Cancer dataset\n",
    "\n",
    "Their healthy samples should only come from Emerson et al. 2017 \n",
    "\n",
    "\n",
    "Since there are so few in McPas and db_pos, make an aggregate of maximum of cancer sequences as possible. \n",
    "\n",
    "First, adding McPas and DB_pos, then checking with training/testing datasets of tumor samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "martial-enlargement",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi\\Anaconda3\\envs\\pdm\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (12,13,14,22,23) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "mcpas = pd.read_csv('../training_data_new/new_data/McPas-TCR.csv', \n",
    "                    usecols = ['CDR3.beta.aa', 'Species', 'Category', 'Epitope.peptide', \n",
    "                               'Epitope.ID', 'MHC','Tissue','TRBV', 'TRBD', 'TRBJ'])\\\n",
    "          .rename(columns={'CDR3.beta.aa':'amino_acid'})\\\n",
    "          .query('Species==\"Human\"')\n",
    "mcpas = filter_df(mcpas)\n",
    "mcpas['label'] = mcpas.apply(lambda x : 1 if x['Category'] == 'Cancer' else 0, axis=1)\n",
    "mcpas_cancer = mcpas.query('Species==\"Human\"&Category==\"Cancer\"')\n",
    "\n",
    "db_pos = pd.read_csv('../training_data_new/new_data/db_pos.csv',\n",
    "                     usecols = ['epitope','cdr3_TRB','TRBV','TRBJ'])\\\n",
    "           .rename(columns={'cdr3_TRB':'amino_acid'})\n",
    "db_pos = filter_df(db_pos)\n",
    "db_pos['label'] =db_pos['epitope'].apply(lambda x: epitope_map[x])\n",
    "db_pos_cancer = db_pos.query('label==1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "timely-slovenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4313"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(db_pos_cancer)+len(mcpas_cancer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthetic-joseph",
   "metadata": {},
   "source": [
    "### Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "meaning-issue",
   "metadata": {},
   "outputs": [],
   "source": [
    "class xd(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch version of DeepCAT CNN\n",
    "    seq_len represents the length (# of AAs) of the CDR3 region (L = 12, 13, ..., 16)\n",
    "    When initializing CNN_CDR3, the L should be specified \n",
    "    \"\"\" \n",
    "    def __init__(self, seq_len):\n",
    "        super(xd, self).__init__()\n",
    "        #Convolutions\n",
    "        self.length = seq_len\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=(5,4))\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size = (1,2), stride=(1,1))\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size = (1,2))\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size = (1,2), stride=(1,1))\n",
    "        #Getting the dimension after convolutions\n",
    "        self.dummy_param = nn.Parameter(torch.empty(0))\n",
    "        self.name = 'var_atchley_net_'+str(seq_len)\n",
    "        #Linear/Dense layers\n",
    "        #self.fc1 = nn.Linear(16*4*2, 10)\n",
    "        self.fc1 = nn.Linear(16*(seq_len-6), 50)\n",
    "        self.bn1 = nn.BatchNorm1d(50)\n",
    "        self.fc2 = nn.Linear(50,10)\n",
    "        self.bn2 = nn.BatchNorm1d(10)\n",
    "        self.fc3 = nn.Linear(10,2)\n",
    "        self.dropout= nn.Dropout(0.4)\n",
    "            \n",
    "    def reset_parameters(self):\n",
    "        for layer in self.children():\n",
    "            if hasattr(layer, 'reset_parameters'):\n",
    "                layer.reset_parameters()\n",
    "                layer.zero_grad()\n",
    "                \n",
    "    def forward(self, x):\n",
    "        #Conv -> ReLU -> MaxPool\n",
    "        print(\"in\", x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        print(\"after conv1\",x.shape)\n",
    "        x = self.pool1(x)\n",
    "        print(\"after pool1\", x.shape)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        print(\"after conv2\", x.shape)\n",
    "        x = self.pool2(x)\n",
    "        print(\"after pool2\", x.shape)\n",
    "        #Linear->ReLU->Dropou\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3]) #reshaping after convolution\n",
    "        print(\"after reshape\", x.shape)\n",
    "        x = self.dropout(self.bn1(F.relu(self.fc1(x)))) \n",
    "        x = self.dropout(self.bn2(F.relu(self.fc2(x)))) \n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        \n",
    "        predictions = x.argmax(1)\n",
    "        probabilities = x.softmax(1)\n",
    "\n",
    "        return x, predictions, probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "prepared-investigator",
   "metadata": {},
   "outputs": [],
   "source": [
    "z=nn.Sequential(nn.Linear(100,20),\n",
    "              nn.BatchNorm1d(20),\n",
    "              nn.Linear(20,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "romantic-joseph",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 50])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z(torch.empty((1000,100))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "necessary-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in torch.Size([100, 1, 5, 12])\n",
      "after conv1 torch.Size([100, 8, 1, 9])\n",
      "after pool1 torch.Size([100, 8, 1, 8])\n",
      "after conv2 torch.Size([100, 16, 1, 7])\n",
      "after pool2 torch.Size([100, 16, 1, 6])\n",
      "after reshape torch.Size([100, 96])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = 12\n",
    "X = torch.empty((100,1,5,L))\n",
    "mod = xd(L)\n",
    "\n",
    "mod(X)[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-power",
   "metadata": {},
   "source": [
    "python train.py -indir .\\training_data_new\\dataset4\\ -arch xd -enc atchley -scale minmax -test True -plots True -lr 5e-5 -nb_epochs 1000 -batchsize 200 -outdir 'dataset4_xdmm_5feats'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescription-prior",
   "metadata": {},
   "source": [
    "python train.py -indir .\\training_data_new\\dataset4\\ -arch xd2 -enc atchley -scale minmax -test True -plots True -lr 1e-4 -nb_epochs 1000 -batchsize 300 -outdir 'dataset4_xd2_mm_5feats'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
