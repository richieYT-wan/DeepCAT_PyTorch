{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pending-merchant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using : cuda\n"
     ]
    }
   ],
   "source": [
    "#Allows relative imports\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports \n",
    "from src.preprocessing import *\n",
    "from src.models import deepcat_cnn\n",
    "from src.torch_util import *\n",
    "from src.dataloader import *\n",
    "from src.train_eval_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#checking gpu status\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "from torch.utils.data import BatchSampler, RandomSampler    \n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "RANGE = range(12,17)\n",
    "TRAINDIR = '../TrainingData/'\n",
    "files = os.listdir(TRAINDIR)\n",
    "files.remove('readme.md')\n",
    "#Reading data\n",
    "train_normal = read_seq(TRAINDIR+files[0])\n",
    "train_tumor = read_seq(TRAINDIR+files[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-nature",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def PredictCancer(f,dir_prefix):\n",
    "    ## f: input iSMART result file\n",
    "    ## N: top N most frequent CDR3s will be included in the analysis\n",
    "    gf=open(f)\n",
    "    CDR3s=[]\n",
    "    for ll in gf.readlines():\n",
    "        cc=ll.strip().split('\\t')[0]\n",
    "        if not cc.startswith('C') or not cc.endswith('F'):\n",
    "            continue\n",
    "        CDR3s.append(cc)\n",
    "    CDR3sDict={}\n",
    "    for cc in CDR3s:\n",
    "        if len(pat.findall(cc))>0:\n",
    "            continue\n",
    "        ll=len(cc)\n",
    "        ccF=AAindexEncoding(cc)\n",
    "        if ll not in CDR3sDict:\n",
    "            CDR3sDict[ll]=[ccF]\n",
    "        else:\n",
    "            CDR3sDict[ll].append(ccF)\n",
    "    ScoreDict={}\n",
    "    XX=[]\n",
    "    for LL in range(12,17):\n",
    "        CDR3_classifier=tf.estimator.Estimator(model_fn=ModelDict[LL],model_dir=dir_prefix+'/CDR3_classifier_PCA_LL'+str(LL)+'_L2_k2f8d10_tCi01'+'/')\n",
    "        if LL in CDR3sDict:\n",
    "            eval_input_fn=tf.estimator.inputs.numpy_input_fn(\n",
    "                x={'x':np.array(CDR3sDict[LL])},        \n",
    "                num_epochs=1,\n",
    "                shuffle=False)\n",
    "        else:\n",
    "            continue\n",
    "        eval_results=CDR3_classifier.predict(input_fn=eval_input_fn)\n",
    "        xx=[]\n",
    "        for x in eval_results:\n",
    "            xx.append(x['probabilities'][1])\n",
    "        ScoreDict[LL]=xx\n",
    "        XX+=xx\n",
    "    mms=[]\n",
    "    for kk in ScoreDict:\n",
    "        mms.append((kk,np.mean(ScoreDict[kk])))\n",
    "    CancerScore=np.mean(XX)\n",
    "    return CancerScore,XX\n",
    "\n",
    "#    return mms, XX, ScoreDict, CancerScore\n",
    "\n",
    "def PredictBatch(DIR, dir_prefix=curPath+'/tmp/'):\n",
    "    ffs=os.listdir(DIR)\n",
    "    mmsList=[]\n",
    "    SDList=[]\n",
    "    XXList=[]\n",
    "    for ff in ffs:\n",
    "        mms, XX, SD=PredictCancer(DIR+ff, dir_prefix=dir_prefix)\n",
    "        mmsList.append(mms)\n",
    "        SDList.append(SD)\n",
    "        XXList.append(XX)\n",
    "    return ffs, mmsList, SDList, XXList\n",
    "    \n",
    "if len(sys.argv) > 1:   \n",
    " DIR=sys.argv[1]\n",
    " DIR1=os.path.basename(DIR)\n",
    " ffs=os.listdir(DIR)\n",
    " dir_prefix=sys.argv[2]\n",
    " CC=[]\n",
    " ffss=[]\n",
    " for ff in ffs:\n",
    "   if ff == 'README.md':\n",
    "     continue\n",
    "   else: \n",
    "     score,XX1 = PredictCancer(DIR+'/'+ff, dir_prefix+'/tmp/')\n",
    "     CC.append(score)\n",
    "     ffss.append(ff)  \n",
    " CC=np.array(CC)\n",
    " ffss=np.array(ffss)\n",
    " if sys.argv[3] == '-t':\n",
    "   with open('Cancer_score_'+DIR1+'.txt', 'w') as f:\n",
    "      writer = csv.writer(f, delimiter='\\t')\n",
    "      writer.writerows(zip(ffss,CC))  \n",
    " elif sys.argv[3] == '-r':       \n",
    "   with open('Cancer_score.txt', 'w') as f:\n",
    "      writer = csv.writer(f, delimiter='\\t')\n",
    "      writer.writerows(zip(ffss,CC))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cardiac-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_seq_ismart(filename):\n",
    "    \"\"\"\n",
    "    Read sequences from a txt, and returns an array of the sequences.\n",
    "    Using numpy arrays because of easier fancy indexing when generating data from sequences\n",
    "    \"\"\"\n",
    "    if '.txt' not in filename:\n",
    "        print(\"Non .txt file given, exiting\")\n",
    "        return\n",
    "\n",
    "    data = []\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f.readlines():\n",
    "            seq = line.strip()\n",
    "            if not seq.startswith('C') or not seq.endswith('F'):continue\n",
    "            data.append(seq)\n",
    "    return np.array(data)\n",
    "\n",
    "def aaindex_encoding(seq, device):\n",
    "    \"\"\"Encodes the AA indices to a given sequence\"\"\"\n",
    "    n_aa = len(seq)\n",
    "    temp = np.zeros([n_aa, n_feats], dtype=np.float32)\n",
    "    for idx in range(n_aa):\n",
    "        aa = seq[idx]\n",
    "        temp[idx] = AAidx_Dict[aa]\n",
    "    temp = np.transpose(temp)\n",
    "    aa_encoding = torch.from_numpy(temp)\n",
    "    aa_encoding = aa_encoding.unsqueeze(0)\n",
    "    if device == torch.device('cuda'):\n",
    "        aa_encoding = aa_encoding.to(device)\n",
    "    return aa_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "formed-portsmouth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['README.md', 'TestReal-BR01B.tsv_ClusteredCDR3s_7.5.txt', 'TestReal-BR05B.tsv_ClusteredCDR3s_7.5.txt', 'TestReal-BR07B.tsv_ClusteredCDR3s_7.5.txt', 'TestReal-BR13B.tsv_ClusteredCDR3s_7.5.txt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aminoAcid</th>\n",
       "      <th>vMaxResolved</th>\n",
       "      <th>frequencyCount....</th>\n",
       "      <th>Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CASSLELGALGGNTIYF</td>\n",
       "      <td>TCRBV07-09</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CASSLELGALGGNTIYF</td>\n",
       "      <td>TCRBV07-09</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CASGTSGFTDTQYF</td>\n",
       "      <td>TCRBV30-01*01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CAWRTSGLTDTQYF</td>\n",
       "      <td>TCRBV30-01*01</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSVGGGGFNEKLFF</td>\n",
       "      <td>TCRBV29-01*01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           aminoAcid   vMaxResolved  frequencyCount....  Group\n",
       "0  CASSLELGALGGNTIYF     TCRBV07-09            0.000133      1\n",
       "1  CASSLELGALGGNTIYF     TCRBV07-09            0.000063      1\n",
       "2     CASGTSGFTDTQYF  TCRBV30-01*01            0.000008      2\n",
       "3     CAWRTSGLTDTQYF  TCRBV30-01*01            0.000008      2\n",
       "4     CSVGGGGFNEKLFF  TCRBV29-01*01            0.000016      3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['CASSLELGALGGNTIYF', 'CASSLELGALGGNTIYF', 'CASGTSGFTDTQYF',\n",
       "       'CAWRTSGLTDTQYF', 'CSVGGGGFNEKLFF', 'CSVVGGGFNEKLFF',\n",
       "       'CASSLVSANYGYTF', 'CASSLVSANYGYTF', 'CASSSRGGYTEAFF',\n",
       "       'CASSSRGGYTEAFF'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path = '../SampleData/Cancer/'\n",
    "print(os.listdir(path)[0:5])\n",
    "files = [x for x in os.listdir(path) if x.endswith('.txt')]\n",
    "data = pd.read_csv(os.path.join(path,files[0]), sep='\\t', header = 0)\n",
    "display(data.head())\n",
    "data['aminoAcid'].values[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "occupational-lebanon",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CASSLELGALGGNTIYF', 'CASSLELGALGGNTIYF', 'CASGTSGFTDTQYF',\n",
       "       'CAWRTSGLTDTQYF', 'CSVGGGGFNEKLFF', 'CSVVGGGFNEKLFF',\n",
       "       'CASSLVSANYGYTF', 'CASSLVSANYGYTF', 'CASSSRGGYTEAFF',\n",
       "       'CASSSRGGYTEAFF', 'CASSLNLASYEQYF', 'CASSLGLASYEQYF',\n",
       "       'CASSETASGNTIYF', 'CASSETASGNTIYF', 'CASSLGQGGYEQYF',\n",
       "       'CASSLSQGGYEQYF', 'CASSPTGGNQPQHF', 'CASSPSGGNQPQHF',\n",
       "       'CAWAGTSNTGELFF', 'CACRGTGNTGELFF', 'CASSPGQGVYEQYF',\n",
       "       'CASSPGQGAYEQYF', 'CASSLSRSNQPQHF', 'CASSLSRSNQPQHF',\n",
       "       'CASSLQGAMETQYF', 'CASSLQGAQETQYF', 'CASSLQGRNQPQHF',\n",
       "       'CASSLRGRNQPQHF', 'CSVWDRGGNQPQHF', 'CSAWDRAGNQPQHF',\n",
       "       'CASSLSRSNQPQHF', 'CASSLDRSNQPQHF', 'CASEVGGSNQPQHF',\n",
       "       'CASSLGGSNQPQHF', 'CASSLSAGGYEQYF', 'CASSLSAGGYEQYF',\n",
       "       'CSVVRGIGTDTQYF', 'CSVERGMGTDTQYF', 'CASSVEPDSYEQYF',\n",
       "       'CASSVEPSSYEQYF', 'CASSPDNSNQPQHF', 'CASSPDSSNQPQHF',\n",
       "       'CSVGSGGTNEKLFF', 'CSVGTGGTNEKLFF', 'CSVGTGNTNEKLFF',\n",
       "       'CSVEKQINTGELFF', 'CSVEKQLNTGELFF', 'CSALRDRSSYEQYF',\n",
       "       'CSVKRDRDSYEQYF', 'CASSEGPSGYEQYF', 'CASSEGPGGYEQFF',\n",
       "       'CASSVAGGPDTQYF', 'CASSVAGGPDTQYF', 'CASSPGGGGYEQYF',\n",
       "       'CASSPGAGGYEQYF', 'CASSLDRPGELFF', 'CASSLDRPGELFF',\n",
       "       'CSVDRGRGTEAFF', 'CSVDRGQGTEAFF', 'CAWSVKGDTEAFF', 'CAWSVRGDTEAFF',\n",
       "       'CASSIRSAYEQYF', 'CASSIRSSYEQYF', 'CAWKGQENTEAFF', 'CAWSGQDNTEAFF',\n",
       "       'CSVRDNYNQPQHF', 'CSARDNHNQPQHF', 'CAWRRGAGNTIYF', 'CAWNRGSGNTIYF',\n",
       "       'CAWSQGAGNTIYF', 'CASSPAPNQPQHF', 'CASSPAPNQPQHF', 'CAFEREGRNEQFF',\n",
       "       'CASEREGRNEQFF', 'CASRLTGNQPQHF', 'CASSLTGNQPQHF', 'CASSLGSNQPQHF',\n",
       "       'CASSLGANQPQHF', 'CASSLSVNTEAFF', 'CASSLSVNTEAFF', 'CASSPPSTDTQYF',\n",
       "       'CASSPPSTDTQYF', 'CAGMTGSGNTIYF', 'CAWSTGNGNTIYF', 'CASSLEGNQPQHF',\n",
       "       'CASSLEGNQPQHF', 'CASTEGINTEAFF', 'CASSEGLNTEAFF', 'CASSLGSNYEQYF',\n",
       "       'CASSLGSSYEQYF', 'CASSLGSSYEQYF', 'CASSLGGNQPQHF', 'CASTLGGHQPQHF',\n",
       "       'CASSLDRPGELFF', 'CASSLDRPGELFF', 'CSVGGEGNQPQHF', 'CSTGGEGNQPQHF',\n",
       "       'CSACGQGNQPQHF', 'CASSDQGNYGYTF', 'CASSDRGNYGYTF', 'CSVTGTGAYEQYF',\n",
       "       'CSVGGTGSYEQYF', 'CASSVGGSGELFF', 'CASSVGGTGELFF', 'CSVSGQLNTEAFF',\n",
       "       'CSVEGQMNTEAFF', 'CASSLEGSYEQYF', 'CASSLQGSYEQYF', 'CAWSVQGDQPQHF',\n",
       "       'CAWSVQGNQPQHF', 'CSVTGQGNTEAFF', 'CSGVGQGDTEAFF', 'CAWNPGMNTEAFF',\n",
       "       'CAWTPGVNTEAFF', 'CASSLDRPGELFF', 'CASSLDRPGELFF', 'CASSLDRPGELFF',\n",
       "       'CASRQDRATNQPQHF', 'CASSQDRASNQPQHF', 'CATSRDPVSTDTQYF',\n",
       "       'CATSRDPVSTDTQYF', 'CATSSSGKNTGELFF', 'CAISSSGRNTGELFF',\n",
       "       'CASSSPGQGSYEQYF', 'CASSSPGQGAYEQYF', 'CASSEADFVNTEAFF',\n",
       "       'CASSEADFVNTEAFF', 'CASSVDGTDYNEQFF', 'CASSVDGTDYNEQFF',\n",
       "       'CASSLGTGPYNEQFF', 'CASSLGVGPYNEQFF', 'CASSLVAGSSYEQYF',\n",
       "       'CASSLLAGSSYEQYF', 'CASSLVAGGSYEQYF', 'CASSLGPGQYNEQFF',\n",
       "       'CASSLGPGKYNEQFF', 'CAWSRDSGSGNTIYF', 'CAWSRDSGAGNTIYF',\n",
       "       'CASSSPGRGTDTQYF', 'CASSSPGRGTDTQYF', 'CASSSPGRGTDTQYF',\n",
       "       'CASSSPGRGTDTQYF', 'CASSLGGASNQPQHF', 'CASSLGGASNQPQHF',\n",
       "       'CASSQGPGTGYGYTF', 'CASSQGPGTNYGYTF', 'CASSQGTSGTSEQYF',\n",
       "       'CASSQGTSGTSEQFF', 'CASSYTTGSDQPQHF', 'CASSYTTGGDQPQHF',\n",
       "       'CASSLAGGAQETQYF', 'CASSLAGGAEETQYF', 'CAWSAGSSSNQPQHF',\n",
       "       'CAWSAGSNSNQPQHF', 'CASSLQLGARTEAFF', 'CASSLQLGARTEAFF',\n",
       "       'CASSSGRVATNEKLFF', 'CASSSGQVATNEKLFF', 'CASSVGVAGNTGELFF',\n",
       "       'CASSVGLAGNTGELFF', 'CASSQDQGSGANVLTF', 'CASSQDTGSGANVLTF',\n",
       "       'CASSLEYGSRPYEQYF', 'CASSLEYGSRPYEQYF', 'CASSQDLPGQLYRNTEAFF',\n",
       "       'CASSQDLPGQLYRNTEAFF', 'CASSQDLPGQLYRNTEAFF',\n",
       "       'CASSQDLPGQLYRNTEAFF', 'CASSLAPTSGPQETQYF', 'CASSLAPTSGPQETQYF',\n",
       "       'CASSLENQPQHF', 'CASSLENQPQHF', 'CASSILTSGSGTDTQYF',\n",
       "       'CASSILTSGSGTDTQYF', 'CASSFISTAAFF', 'CASSFISTAAFF',\n",
       "       'CASSPGWNEQFF', 'CASSPGWNEQFF', 'CAWSGGSYEQYF', 'CAWSGGAYEQYF',\n",
       "       'CAWKGGAYEQYF', 'CASTGASYEQYF', 'CASTGSSYEQYF', 'CASSLGGYGYTF',\n",
       "       'CASSIGGYGYTF', 'CASSPSRNTEAFF', 'CASSPSRNTEAFF', 'CASSPSRNTEAFF',\n",
       "       'CSVSDPNQPQHF', 'CSVAEPNQPQHF', 'CASSFLYEQYF', 'CASSFLYEQYF',\n",
       "       'CASSFLYEQYF', 'CASSLTYEQYF', 'CASSLTYEQYF', 'CSVGDTGQPQHF',\n",
       "       'CSGGDSGQPQHF', 'CASSPPTESYGYTF', 'CASSPPTESYGYTF', 'CASSIPYNEQFF',\n",
       "       'CASSIPYNEQFF', 'CASSIPYNEQFF', 'CASSSRGMNDEQYF', 'CASSSRGMNDEQYF',\n",
       "       'CAWSVARNTEAFF', 'CAWSVARNTEAFF', 'CAWSVLSRPQHF', 'CAWSVLSQPQHF',\n",
       "       'CSVGGGTDTQYF', 'CSVAGGTDTQYF', 'CASSYFTDTQYF', 'CASSYFTDTQYF',\n",
       "       'CASSAGSEQYF', 'CASSAGSEQYF', 'CAWSQGEGDTQYF', 'CAWSRGEGDTQYF',\n",
       "       'CASSFRETQYF', 'CASSFRETQYF', 'CAWAGGNTEAFF', 'CASGGGNTEAFF',\n",
       "       'CASSTGVYGYTF', 'CASSTGVYGYTF', 'CASSTGVYGYTF', 'CASSGTSYGYTF',\n",
       "       'CASSGSSYGYTF', 'CASSISLGSEQYF', 'CASSISLGAEQYF', 'CASSEGGDGYTF',\n",
       "       'CASSEGGDGYTF', 'CASSISVYGYTF', 'CASSISVYGYTF', 'CASSPRWGGEKLFF',\n",
       "       'CASSPRWGGEKLFF', 'CASSLLGEQYF', 'CASSLLGEQFF', 'CSVGTSGFYEQYF',\n",
       "       'CSVGTSGFYEQYF', 'CAWKTSGANVLTF', 'CAWQSSGANVLTF', 'CAWDNSGANVLTF',\n",
       "       'CAWRSAGPGTYTF', 'CAWRSAGPGTYTF', 'CASSVEGVNTIYF', 'CASSVEGVNTIYF',\n",
       "       'CASSQDLAGGLLSYEQYF', 'CASSQDLAGGLLNYEQYF', 'CASARAYEQYF',\n",
       "       'CASRRAYEQYF', 'CSARPQETQYF', 'CSARPEETQYF', 'CSVVQGDYGYTF',\n",
       "       'CSVDQGDYGYTF', 'CAWSSGAHEQYF', 'CARSTGAHEQYF', 'CSVAGQGYEQYF',\n",
       "       'CSVEGQGYEQYF', 'CSVTRDYEQYF', 'CSVRRDYEQYF', 'CSVEVGGYEQYF',\n",
       "       'CSVAVGGYEQYF', 'CSVYRGGNEQYF', 'CSVGRGGNEQFF', 'CAWSAGTSDTQYF',\n",
       "       'CAWNSGTSDTQYF'], dtype=object)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = data['aminoAcid'].str.startswith('C') & data['aminoAcid'].str.endswith('F')\n",
    "data[mask]['aminoAcid'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-framework",
   "metadata": {},
   "source": [
    "### to read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "identical-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TestReal-BR01B.tsv_ClusteredCDR3s_7.5.txt'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(os.path.join(path,files[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dynamic-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [x for x in os.listdir(path) if x.endswith('.txt')]\n",
    "\n",
    "for f in files:\n",
    "    data = pd.read_csv(os.path.join(path,files[0]), sep='\\t', header = 0)\n",
    "    #seqs = data['aminoAcid'] #An array containing sequences as str\n",
    "    mask = data['aminoAcid'].str.startswith('C') & data['aminoAcid'].str.endswith('F')\n",
    "    seqs = data[mask]['aminoAcid'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "developmental-swedish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ismart(filename):\n",
    "    \"\"\"\n",
    "    Reads a .txt file, assumes that it is in the format outputed by iSMARTm.py\n",
    "    Returns a numpy array to be used for aaindex_encoding()\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(filename, sep='\\t', header=0)\n",
    "    data['len'] = data.apply(lambda x: len(x['aminoAcid']),axis=1)\n",
    "    data = data.query('len>=12 & len<=16').copy()\n",
    "    mask = data['aminoAcid'].str.startswith('C') & data['aminoAcid'].str.endswith('F')\n",
    "    data = data[mask].sort_values('len', ascending=True).copy()\n",
    "    seqs = data['aminoAcid'].copy().values\n",
    "    return seqs, data\n",
    "\n",
    "def generate_features(sequences, keys = range(12,17), device = None, shuffle=False):\n",
    "    \"\"\"\n",
    "    Takes a np.array, returns a dictionnary.\n",
    "    Behaves like generate_features_labels except that it doesn't have a label.\n",
    "    \"\"\"\n",
    "    seqlens = np.array([len(seqs) for seqs in sequences])\n",
    "    print(\"Getting data\")\n",
    "    feature_dict = {}\n",
    "    #Only keep sequences with length 12 to 16\n",
    "    for length in keys:\n",
    "        #Using numpy to create mask for fancy indexing, converting to tensors later\n",
    "        \n",
    "        mask = np.where(seqlens==length)[0]\n",
    "        #Reusing the code from DeepCAT for Labels\n",
    "        \n",
    "        data = []\n",
    "        for seq in sequences[mask]:\n",
    "            if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "            data.append(aaindex_encoding(seq, 'cpu'))\n",
    "\n",
    "        data = torch.stack(data) #Stack a list of tensors into a single tensor\n",
    "\n",
    "        #Sends to cuda. Shouldn't do this in batch-train because every tensors will be on GPU\n",
    "        #leading to out of memory issues\n",
    "\n",
    "        feature_dict[length] = data\n",
    "        del data\n",
    "        \n",
    "    print(\"Data device =\",feature_dict[12].device)\n",
    "    print(\"Done loading, returning features\")\n",
    "    return feature_dict\n",
    "\n",
    "def aaindex_encoding(seq, device='cuda'):\n",
    "    \"\"\"Encodes the AA indices to a given sequence\"\"\"\n",
    "    n_aa = len(seq)\n",
    "    temp = np.zeros([n_aa, n_feats], dtype=np.float32)\n",
    "    for idx in range(n_aa):\n",
    "        aa = seq[idx]\n",
    "        temp[idx] = AAidx_Dict[aa]\n",
    "    temp = np.transpose(temp)\n",
    "    aa_encoding = torch.from_numpy(temp)\n",
    "    aa_encoding = aa_encoding.unsqueeze(0)\n",
    "    if device == torch.device('cuda'):\n",
    "        aa_encoding = aa_encoding.to(device)\n",
    "    return aa_encoding\n",
    "\n",
    "def get_data_df(filename):\n",
    "    _, df = read_ismart(filename)\n",
    "    df['len'] = df.apply(lambda x: len(x['aminoAcid']),axis=1)\n",
    "    df = df.query('len>=12 & len<=16').copy()\n",
    "    df['features'] = df['aminoAcid'].apply(aaindex_encoding)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legal-colon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_features(sequences, keys = range(12,17), device = None, shuffle=False):\n",
    "    \"\"\"\n",
    "    Takes a np.array, returns a dictionnary.\n",
    "    Behaves like generate_features_labels except that it doesn't have a label.\n",
    "    \"\"\"\n",
    "    seqlens = np.array([len(seqs) for seqs in sequences])\n",
    "    print(\"Getting data\")\n",
    "    feature_dict = {}\n",
    "    #Only keep sequences with length 12 to 16\n",
    "    for length in keys:\n",
    "        #Using numpy to create mask for fancy indexing, converting to tensors later\n",
    "        \n",
    "        mask = np.where(seqlens==length)[0]\n",
    "        #Reusing the code from DeepCAT for Labels\n",
    "        \n",
    "        data = []\n",
    "        for seq in sequences[mask]:\n",
    "            if len(PAT.findall(seqs))>0:continue #Skipping a sequence if it matches an unwanted CDR3 pattern \n",
    "            data.append(aaindex_encoding(seq, 'cpu'))\n",
    "\n",
    "        data = torch.stack(data) #Stack a list of tensors into a single tensor\n",
    "\n",
    "        #Sends to cuda. Shouldn't do this in batch-train because every tensors will be on GPU\n",
    "        #leading to out of memory issues\n",
    "\n",
    "        feature_dict[length] = data\n",
    "        del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "national-gravity",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for seq in df.query('len==12')['aminoAcid'].values:\n",
    "    feats.append(aaindex_encoding(seq))\n",
    "feats = torch.stack(feats).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "distinct-teens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([47, 1, 15, 12])"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "considerable-fellowship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feats_tensor(sequences, device):\n",
    "    \"Sequences : numpy array\"\n",
    "    feats = []\n",
    "    for seq in sequences:\n",
    "        feats.append(aaindex_encoding(seq))\n",
    "    feats = torch.stack(feats).to('cuda')\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "interim-document",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models & weights loaded\n"
     ]
    }
   ],
   "source": [
    "#Here for a single file\n",
    "models = load_models([12,13,14,15,16],'../output/testplots/')\n",
    "#set all models to eval\n",
    "for k in keys:\n",
    "    models[k].eval()\n",
    "    models[k].to('cuda')\n",
    "    \n",
    "_, df = read_ismart(os.path.join(path,files[0])) #sorts the df by Length\n",
    "\n",
    "df['prob_cancer']=None\n",
    "for l in [12,13,14,15,16]:\n",
    "    seqs=df.query('len==@l')['aminoAcid'].values\n",
    "    feats = get_feats_tensor(seqs, device='cuda')\n",
    "    logit, predictions, probs = models[l](feats)\n",
    "    df.loc[df['len']==12,'prob_cancer'] = probs.detach().cpu()[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "joined-richardson",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aminoAcid</th>\n",
       "      <th>vMaxResolved</th>\n",
       "      <th>frequencyCount....</th>\n",
       "      <th>Group</th>\n",
       "      <th>len</th>\n",
       "      <th>prob_cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>CASSLENQPQHF</td>\n",
       "      <td>TCRBV07-02*01</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>81</td>\n",
       "      <td>12</td>\n",
       "      <td>0.007298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>CASSGSSYGYTF</td>\n",
       "      <td>TCRBV06-01*01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>0.015095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>CASSGTSYGYTF</td>\n",
       "      <td>TCRBV06-01*01</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>105</td>\n",
       "      <td>12</td>\n",
       "      <td>0.023348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>CASSTGVYGYTF</td>\n",
       "      <td>TCRBV19-01</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>104</td>\n",
       "      <td>12</td>\n",
       "      <td>0.165869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>CASSTGVYGYTF</td>\n",
       "      <td>TCRBV19-01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>104</td>\n",
       "      <td>12</td>\n",
       "      <td>0.165869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>CASSVGVAGNTGELFF</td>\n",
       "      <td>TCRBV09-01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "      <td>0.453133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>CASSVGLAGNTGELFF</td>\n",
       "      <td>TCRBV09-01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>76</td>\n",
       "      <td>16</td>\n",
       "      <td>0.223772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>CASSQDTGSGANVLTF</td>\n",
       "      <td>TCRBV04-03*01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.020113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>CASSLEYGSRPYEQYF</td>\n",
       "      <td>TCRBV07-02*01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>78</td>\n",
       "      <td>16</td>\n",
       "      <td>0.453133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>CASSQDQGSGANVLTF</td>\n",
       "      <td>TCRBV04-03*01</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.021733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>235 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            aminoAcid   vMaxResolved  frequencyCount....  Group  len  \\\n",
       "170      CASSLENQPQHF  TCRBV07-02*01            0.001300     81   12   \n",
       "224      CASSGSSYGYTF  TCRBV06-01*01            0.000016    105   12   \n",
       "223      CASSGTSYGYTF  TCRBV06-01*01            0.000039    105   12   \n",
       "222      CASSTGVYGYTF     TCRBV19-01            0.000039    104   12   \n",
       "221      CASSTGVYGYTF     TCRBV19-01            0.000016    104   12   \n",
       "..                ...            ...                 ...    ...  ...   \n",
       "158  CASSVGVAGNTGELFF     TCRBV09-01            0.000016     76   16   \n",
       "159  CASSVGLAGNTGELFF     TCRBV09-01            0.000016     76   16   \n",
       "161  CASSQDTGSGANVLTF  TCRBV04-03*01            0.000016     77   16   \n",
       "163  CASSLEYGSRPYEQYF  TCRBV07-02*01            0.000016     78   16   \n",
       "160  CASSQDQGSGANVLTF  TCRBV04-03*01            0.000016     77   16   \n",
       "\n",
       "    prob_cancer  \n",
       "170    0.007298  \n",
       "224    0.015095  \n",
       "223    0.023348  \n",
       "222    0.165869  \n",
       "221    0.165869  \n",
       "..          ...  \n",
       "158    0.453133  \n",
       "159    0.223772  \n",
       "161    0.020113  \n",
       "163    0.453133  \n",
       "160    0.021733  \n",
       "\n",
       "[235 rows x 6 columns]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stuff(filename):\n",
    "    _, df = read_ismart(filename) #sorts the df by Length\n",
    "    df['prob_cancer']=None\n",
    "    for l in [12,13,14,15,16]:\n",
    "        seqs=df.query('len==@l')['aminoAcid'].values\n",
    "        feats = get_feats_tensor(seqs, device='cuda')\n",
    "        logit, predictions, probs = models[l](feats)\n",
    "        df.loc[df['len']==l,'prob_cancer'] = probs.detach().cpu()[:,1]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "normal-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../SampleData/Cancer/'"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "magnetic-catering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../SampleData/Cancer\n",
      "../SampleData/Control\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir('../SampleData/'):\n",
    "    print(os.path.join('../SampleData/',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "verbal-model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../SampleData/Cancer/', '../SampleData/Cancer')"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path, os.path.dirname(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "former-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in os.listdir('../SampleData/'): #For each folder in in_directory\n",
    "    subfolderpath = os.path.join('../SampleData', subfolder)#Get path to subfolder\n",
    "    files = [os.path.join(subfolderpath,x) for x in os.listdir(subfolderpath) if x.endswith('.txt')] #Ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "binary-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = range(0,30)\n",
    "MAPPING = {os.path.basename(file):cancer_score for (file,cancer_score) in zip(files,scores)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "remarkable-fourth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Control'"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(subfolderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "indian-enclosure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cancer'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(os.path.dirname(path))#(os.path.join(path,files[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "functioning-dominant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3295363025198227\n",
      "0.2181643886145523\n"
     ]
    }
   ],
   "source": [
    "cancer = stuff(os.path.join(path,files[4]))\n",
    "non = stuff('../SampleData/Control/TestReal-HIP09029.tsv_ClusteredCDR3s_7.5.txt')\n",
    "print(np.mean(cancer['prob_cancer']))\n",
    "print(np.mean(non['prob_cancer']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-trance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Cancer_score_'+DIR1+'.txt', 'w') as f:\n",
    "      writer = csv.writer(f, delimiter='\\t')\n",
    "      writer.writerows(zip(ffss,CC))  \n",
    " elif sys.argv[3] == '-r':       \n",
    "   with open('Cancer_score.txt', 'w') as f:\n",
    "      writer = csv.writer(f, delimiter='\\t')\n",
    "      writer.writerows(zip(ffss,CC))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
