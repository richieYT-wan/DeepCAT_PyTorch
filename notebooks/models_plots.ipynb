{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "particular-detective",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Using : cuda\n",
      "Getting data\n",
      "Data device = cpu\n",
      "Done loading, returning features and labels.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NormalCDR3.txt',\n",
       " 'NormalCDR3_test.txt',\n",
       " 'TumorCDR3.txt',\n",
       " 'TumorCDR3_test.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Allows relative imports\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "#imports \n",
    "from src.preprocessing import *\n",
    "from src.models import *\n",
    "from src.torch_util import *\n",
    "from src.dataloader import *\n",
    "from src.train_eval_helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "#checking gpu status\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 150\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"Using : {}\".format(device))\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using : {}\".format(device))\n",
    "    \n",
    "RANGE = range(12,17)\n",
    "#Reading data\n",
    "TRAINDIR = '../TrainingData/'\n",
    "files = os.listdir(TRAINDIR)\n",
    "files = [f for f in files if '.txt' in f]\n",
    "TRAINDIR+files[0]\n",
    "train_normal = read_seq(TRAINDIR+files[0])\n",
    "train_tumor = read_seq(TRAINDIR+files[2])\n",
    "\n",
    "train_feats, train_labels = generate_features_labels(train_tumor, train_normal)\n",
    "#files.remve('readme.md')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "verified-reserve",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepcat_cnn_12_best_val.pth.tar',\n",
       " 'deepcat_cnn_13_best_val.pth.tar',\n",
       " 'deepcat_cnn_14_best_val.pth.tar',\n",
       " 'deepcat_cnn_15_best_val.pth.tar',\n",
       " 'deepcat_cnn_16_best_val.pth.tar']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '../src/Output/'\n",
    "files = os.listdir(PATH)\n",
    "\n",
    "z = [f for f in files if '.pth.tar' in f]\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lucky-terminal",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['epoch', 'model', 'best_metric', 'state_dict', 'args', 'val_loss', 'acc', 'AUC', 'F1'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod12 = deepcat_cnn(12)\n",
    "chkpt = torch.load(os.path.join(PATH,z[0]))\n",
    "print(chkpt.keys())\n",
    "mod12.load_state_dict(chkpt['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "forced-providence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models loaded\n"
     ]
    }
   ],
   "source": [
    "test_dict2 = load_models([12,13,16], PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tutorial-egyptian",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.5109, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 0.0000],\n",
       "         ...,\n",
       "         [0.0000, 0.0000],\n",
       "         [0.0000, 5.2117],\n",
       "         [0.0000, 0.0000]], grad_fn=<MulBackward0>),\n",
       " tensor([0, 0, 0,  ..., 0, 1, 0]),\n",
       " tensor([[0.9249, 0.0751],\n",
       "         [0.5000, 0.5000],\n",
       "         [0.5000, 0.5000],\n",
       "         ...,\n",
       "         [0.5000, 0.5000],\n",
       "         [0.0054, 0.9946],\n",
       "         [0.5000, 0.5000]], grad_fn=<SoftmaxBackward>))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict2[12](train_feats[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hundred-strength",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d,e = eval_model(test_dict2[12], nn.CrossEntropyLoss(), train_feats[12], train_labels[12], return_curve =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fiscal-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-companion",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
