{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN dimensions stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys,os,re,csv,pathlib\n",
    "\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "c1 = nn.Conv2d(1, 8, kernel_size=(15,2))\n",
    "m1 = nn.MaxPool2d(kernel_size = (1,2))\n",
    "c2 = nn.Conv2d(8, 16, kernel_size = (1,2))\n",
    "m2 = nn.MaxPool2d(kernel_size = (1,2))\n",
    "\n",
    "cnn = nn.Sequential(c1,m1,c2,m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####\n",
      "\n",
      "USING LENGTH =  12\n",
      "Input:  torch.Size([1, 1, 15, 12])\n",
      "After Conv1: torch.Size([1, 8, 1, 11])\n",
      "After Pool1: torch.Size([1, 8, 1, 5])\n",
      "After Conv2: torch.Size([1, 16, 1, 4])\n",
      "After Pool2: torch.Size([1, 16, 1, 2])\n",
      "Dense torch.Size([1, 10])\n",
      "soft tensor([[0.0929, 0.1150, 0.0869, 0.1024, 0.0870, 0.0853, 0.1370, 0.1060, 0.0725,\n",
      "         0.1151]], grad_fn=<SoftmaxBackward>)\n",
      "arg tensor([6])\n",
      "####\n",
      "\n",
      "\n",
      "####\n",
      "\n",
      "USING LENGTH =  13\n",
      "Input:  torch.Size([1, 1, 15, 13])\n",
      "After Conv1: torch.Size([1, 8, 1, 12])\n",
      "After Pool1: torch.Size([1, 8, 1, 6])\n",
      "After Conv2: torch.Size([1, 16, 1, 5])\n",
      "After Pool2: torch.Size([1, 16, 1, 2])\n",
      "Dense torch.Size([1, 10])\n",
      "soft tensor([[0.0969, 0.1168, 0.0839, 0.0816, 0.1263, 0.1539, 0.1043, 0.1046, 0.0517,\n",
      "         0.0800]], grad_fn=<SoftmaxBackward>)\n",
      "arg tensor([5])\n",
      "####\n",
      "\n",
      "\n",
      "####\n",
      "\n",
      "USING LENGTH =  14\n",
      "Input:  torch.Size([1, 1, 15, 14])\n",
      "After Conv1: torch.Size([1, 8, 1, 13])\n",
      "After Pool1: torch.Size([1, 8, 1, 6])\n",
      "After Conv2: torch.Size([1, 16, 1, 5])\n",
      "After Pool2: torch.Size([1, 16, 1, 2])\n",
      "Dense torch.Size([1, 10])\n",
      "soft tensor([[0.0755, 0.1010, 0.1032, 0.0996, 0.1109, 0.0994, 0.1139, 0.0760, 0.1319,\n",
      "         0.0887]], grad_fn=<SoftmaxBackward>)\n",
      "arg tensor([8])\n",
      "####\n",
      "\n",
      "\n",
      "####\n",
      "\n",
      "USING LENGTH =  15\n",
      "Input:  torch.Size([1, 1, 15, 15])\n",
      "After Conv1: torch.Size([1, 8, 1, 14])\n",
      "After Pool1: torch.Size([1, 8, 1, 7])\n",
      "After Conv2: torch.Size([1, 16, 1, 6])\n",
      "After Pool2: torch.Size([1, 16, 1, 3])\n",
      "Dense torch.Size([1, 10])\n",
      "soft tensor([[0.1084, 0.0856, 0.0899, 0.0999, 0.0959, 0.0812, 0.1071, 0.1197, 0.1192,\n",
      "         0.0932]], grad_fn=<SoftmaxBackward>)\n",
      "arg tensor([7])\n",
      "####\n",
      "\n",
      "\n",
      "####\n",
      "\n",
      "USING LENGTH =  16\n",
      "Input:  torch.Size([1, 1, 15, 16])\n",
      "After Conv1: torch.Size([1, 8, 1, 15])\n",
      "After Pool1: torch.Size([1, 8, 1, 7])\n",
      "After Conv2: torch.Size([1, 16, 1, 6])\n",
      "After Pool2: torch.Size([1, 16, 1, 3])\n",
      "Dense torch.Size([1, 10])\n",
      "soft tensor([[0.0902, 0.1176, 0.0941, 0.1054, 0.0936, 0.0894, 0.1269, 0.0940, 0.1138,\n",
      "         0.0751]], grad_fn=<SoftmaxBackward>)\n",
      "arg tensor([6])\n",
      "####\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for z in range(12,17):\n",
    "    print(\"####\\n\\nUSING LENGTH = \",z)\n",
    "    x = torch.rand((1,1,15,z),dtype=torch.float32)\n",
    "    print(\"Input: \",x.shape)\n",
    "    conv1=c1(x)\n",
    "    print(\"After Conv1:\", conv1.shape)\n",
    "    pool1=m1(conv1)\n",
    "    print(\"After Pool1:\", pool1.shape)\n",
    "    conv2=c2(pool1)\n",
    "    print(\"After Conv2:\", conv2.shape)\n",
    "    pool2=m2(conv2)\n",
    "    print(\"After Pool2:\", pool2.shape)\n",
    "    if z<15:\n",
    "        xx = 16*2\n",
    "    elif z>=15:\n",
    "        xx = 16*3\n",
    "    lin = nn.Linear(xx,10)\n",
    "    \n",
    "    dense1= lin(pool2.view(-1,xx))\n",
    "    print(\"Dense\",dense1.shape)\n",
    "    print(\"soft\",dense1.softmax(1))\n",
    "    print(\"arg\",dense1.argmax(1))\n",
    "    print(\"####\\n\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing/AA index stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C\t-8.36918251369427\t8.3031934498954\t-6.6196694564762\t13.8734139891373\t8.59531323791867\t9.79914818190207\t1.26911186662177\t-4.63752901352054\t-0.983921565990354\t4.3634243590938\t2.34365256090458\t0.343445840449375\t1.18290876288827\t0.0132558803925318\t-0.696621502763574\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AAs=np.array(list('WFGAVILMPYSTNQCKRHDE'))\n",
    "curPath=os.getcwd()\n",
    "##AAidx_file='AAindexNormalized.txt' ## AA index reached AUC about 61% for L=14. Worse than AdaBoost\n",
    "##AAidx_file='AtchleyFactors.txt'  ## Atchley factors work worse than using 544 AA index\n",
    "AAidx_file='AAidx_PCA.txt' ## works like a charm!!!\n",
    "gg=open(AAidx_file)\n",
    "AAidx_Names=gg.readline().strip().split('\\t') # Get PC1,... PC15\n",
    "AAidx_Dict={} # Gets the values for each of the 15 features\n",
    "i = 0\n",
    "for ll in gg.readlines():\n",
    "    if i ==4:\n",
    "        print(ll)\n",
    "    \n",
    "    ll=ll.strip().split('\\t')\n",
    "    AA=ll[0]\n",
    "    tag=0\n",
    "    vv=[]\n",
    "    for xx in ll[1:]:\n",
    "        vv.append(float(xx))\n",
    "    if tag==1:\n",
    "        i+=1\n",
    "        continue\n",
    "    i+=1\n",
    "    AAidx_Dict[AA]=vv\n",
    "    \n",
    "Nf=len(AAidx_Dict['C']) #could've just written 15...\n",
    "\n",
    "pat=re.compile('[\\\\*_XB]')  ## non-productive CDR3 patterns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "#Save the output of the mapping AAidx_dict in the beginning of DeepCAT.py\n",
    "with open('AAidx_dict.pkl', 'wb') as f: \n",
    "    pickle.dump(AAidx_Dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32 \n",
      " (20, 15) \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
      " <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "AAs=np.array(list('WFGAVILMPYSTNQCKRHDE'))\n",
    "\n",
    "def OneHotEncoding(Seq):\n",
    "    Seq_aa = list(Seq) \n",
    "    Ns=len(Seq_aa)\n",
    "    OHE=np.zeros([20,Ns])\n",
    "    for ii in range(Ns):\n",
    "        aa=Seq_aa[ii]\n",
    "        vv=np.where(AAs==aa)\n",
    "        OHE[vv,ii]=1\n",
    "    OHE=OHE.astype(np.float32)\n",
    "    return OHE, vv \n",
    "#So in X (row/index) we have the amino acid \n",
    "#And in Y (columns) we have the position in the sequence\n",
    "seq = 'CASSYSTRGGSPLHF'\n",
    "temp, vv = OneHotEncoding(seq)\n",
    "print(temp.dtype,\"\\n\", temp.shape,\"\\n\",temp,\"\\n\",type(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clean_scripts.encoding import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(oneHot_encoding('CASSYSGGSPLHF'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nf = number features = 15\n",
    "Nf=15\n",
    "def AAindexEncoding(Seq):\n",
    "    Ns=len(Seq)\n",
    "    AAE=np.zeros([Ns, Nf])\n",
    "    for kk in range(Ns):\n",
    "        ss=Seq[kk]\n",
    "        #print(ss, kk)\n",
    "        AAE[kk,]=AAidx_Dict[ss]\n",
    "    AAE=np.transpose(AAE.astype(np.float32))\n",
    "    return AAE\n",
    "seq = 'CASSYSGGSPLHF'\n",
    "temp = AAindexEncoding(seq)\n",
    "print(temp,temp.shape)\n",
    "#print(temp.dtype,\"\\n\", temp.shape,\"\\n\",temp,\"\\n\",type(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llt = np.array([12, 13, 14, 12, 12, 15, 15, 15, 12])\n",
    "\n",
    "ll = 12\n",
    "ll1 = 15\n",
    "[1]*len(np.where(llt==ll)[0])+[0]*len(np.where(llt==ll1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetFeatureLabels(TumorCDR3s, NonTumorCDR3s):\n",
    "    nt=len(TumorCDR3s)\n",
    "    nc=len(NonTumorCDR3s)\n",
    "    LLt=[len(ss) for ss in TumorCDR3s]\n",
    "    LLt=np.array(LLt)\n",
    "    LLc=[len(ss) for ss in NonTumorCDR3s]\n",
    "    LLc=np.array(LLc)\n",
    "    NL=range(12,17)\n",
    "    FeatureDict={}\n",
    "    LabelDict={}\n",
    "    for LL in NL:\n",
    "        vvt=np.where(LLt==LL)[0]\n",
    "        vvc=np.where(LLc==LL)[0]\n",
    "        Labels=[1]*len(vvt)+[0]*len(vvc)\n",
    "        Labels=np.array(Labels)\n",
    "        Labels=Labels.astype(np.int32)\n",
    "        data=[]\n",
    "        for ss in TumorCDR3s[vvt]:\n",
    "            if len(pat.findall(ss))>0:\n",
    "                continue\n",
    "            data.append(AAindexEncoding(ss))\n",
    "#            data.append(OneHotEncoding(ss))\n",
    "        for ss in NonTumorCDR3s[vvc]:\n",
    "            if len(pat.findall(ss))>0:\n",
    "                continue\n",
    "            data.append(AAindexEncoding(ss))\n",
    "#            data.append(OneHotEncoding(ss))\n",
    "        data=np.array(data)\n",
    "        features={'x':data,'LL':LL}\n",
    "        FeatureDict[LL]=features\n",
    "        LabelDict[LL]=Labels\n",
    "    return FeatureDict, LabelDict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
